---
title: "432 Class 3 Slides"
author: "github.com/THOMASELOVE/432-2018"
date: "`r Sys.Date()`"
output:
  beamer_presentation:
    theme: "Madrid"
    colortheme: "lily"
    fonttheme: "structurebold"
    fig_caption: FALSE
---

```{r set-options, echo=FALSE, cache=FALSE}
knitr::opts_chunk$set(comment=NA)
options(width = 60)
```

## Setup

```{r, warning = FALSE, message = FALSE}
library(skimr)
library(simputation)
library(broom)
library(modelr)
library(tidyverse)

smartcle1 <- read.csv("data/smartcle1.csv")
```

## Today's Materials

- A linear regression model using factors and quantities as predictors
- Single imputation via the `simputation` package
- Models including product terms
- Interpreting interactions, making predictions
- Centering and Rescaling predictors
- Two-Way Analysis of Variance

These ideas come from Chapters 2-5, mostly.

# Returning to the SMART BRFSS data (Notes Sections 2.8 - 2.11 and 5)

## We're going to build `smartcle3`

We'll use a piece of the `smartcle1` data, and **simply impute** missing values.

Variable | `NA`s | Description
---------: | --: | -----------------------------------------------------
`SEQNO` | 0 | respondent identification number (all begin with 2016)
`bmi` | 84 | Body mass index, in kg/m^2^
`sleephrs` | 8 | On average, how many hours of sleep do you get in a 24-hour period?
`female` | 0 | Sex, 1 = female, 0 = male
`exerany` | 6 | Have you used the internet in the past 30 days? (1 = yes, 0 = no)
`alcdays` | 46 | How many days during the past 30 days did you have at least one drink of any alcoholic beverage such as beer, wine, a malt beverage or liquor?

## `smartcle3` development

```{r create_smartcle3}
set.seed(20180123)

smartcle3 <- smartcle1 %>%
  select(SEQNO, bmi, sleephrs, female, alcdays, exerany) %>%
  impute_rhd(exerany ~ 1) %>%
  impute_pmm(sleephrs ~ 1) %>%
  impute_rlm(bmi ~ female + sleephrs) %>%
  impute_cart(alcdays ~ .) 

colSums(is.na(smartcle3))
```

## `skim(smartcle3)`

![](figs/fig01.png)

# Plot, early and often

## Using `female` to model `bmi`

```{r, echo = FALSE}
ggplot(smartcle3, aes(x = factor(female), y = bmi)) +
  geom_boxplot()
```

## Using `sleephrs` to model `bmi`

```{r, echo = FALSE}
ggplot(smartcle3, aes(x = sleephrs, y = bmi)) +
  geom_point() +
  geom_smooth(method = "lm")
```

## Using `sleephrs` to model `bmi`, stratified by `female`

```{r, echo = FALSE}
ggplot(smartcle3, aes(x = sleephrs, y = bmi, color = factor(female))) +
  geom_point(alpha = 0.5, size = 2)
```

## Using `female` and `sleephrs` and their interaction to model `bmi`

```{r, echo = FALSE}
ggplot(smartcle3, aes(x = sleephrs, y = bmi, color = factor(female))) +
    geom_point() + 
    guides(col = FALSE) +
    geom_smooth(method = "lm", se = FALSE) +
    facet_wrap(~ female, labeller = label_both) 
```

# Incorporating a categorical-quantitative product term in a regression model (See Sections 2.11 - 2.12 and 4)

## Building Two Models

We'll predict `bmi` using `female` and `sleephrs` 

- and their interaction
- without their interaction

```{r}
model_int <- lm(bmi ~ female * sleephrs, data = smartcle3)
model_noint <- lm(bmi ~ female + sleephrs, data = smartcle3)
```

## Comparing Nested Models via `glance`

```{r}
glance(model_int) %>% round(., 3)
glance(model_noint) %>% round(., 3)
```

## ANOVA comparison for nested models

```{r}
anova(model_int, model_noint)
```

## Predictions with `model_int`

```{r}
tidy(model_int)
```

## Interpreting the Interaction model

With interaction, we have... 

`bmi` = 27.95 + 2.47 `female` + 0.04 `sleephrs` - 0.45 `female` x `sleephrs`

- What is the predicted `bmi` for a male who sleeps 10 hours?
- What is the predicted `bmi` for a female who sleeps 10 hours?

## Interpreting the Interaction model

`bmi` = 27.95 + 2.47 `female` + 0.04 `sleephrs` - 0.45 `female` x `sleephrs`

- so for males, our model is: `bmi` = 27.95 + 0.04 `sleephrs`, and
- for females, our model is: `bmi` = 25.48 - 0.41 `sleephrs`

Both the slope and the intercept of the `bmi`-`sleephrs` model **depend** on `sex`

## Predictions with `model_noint`

```{r}
tidy(model_noint)
```

## Interpreting the NO Interaction model

Without interaction, we have... 

`bmi` = 29.79 - 0.67 `female` - 0.22 `sleephrs`

- Now, what is the predicted `bmi` for a male who sleeps 10 hours?
- What is the predicted `bmi` for a female who sleeps 10 hours?

## Interpreting the NO Interaction model

`bmi` = 29.79 - 0.67 `female` - 0.22 `sleephrs`

- so for males, our model is: `bmi` = 29.79 - 0.22 `sleephrs`,
- and for females, our model is: `bmi` = 29.12 - 0.22 `sleephrs`


Only the **intercept** of the `bmi`-`sleephrs` model depends on `sex`

- Change in `bmi` per additional hour of sleep **does not depend** on sex

## Building Predictions for New Data (Individual Subjects)

What do we predict for the `bmi` of a female subject who gets 10 hours of sleep per night? What if the subject was male, instead?

```{r}
new1 <- data_frame(female = c(1, 0), sleephrs = c(10,10))

predict(model_int, newdata = new1, 
        interval = "prediction", level = 0.95)
```

## Building Predictions for New Data (Average Predictions)

What do we predict for the average `bmi` of a population of female subjects who sleep for 10 hours? What about the population of male subjects?

```{r}
new1 <- data_frame(female = c(1, 0), sleephrs = c(10,10))

predict(model_int, newdata = new1, 
        interval = "confidence", level = 0.95)
```

# Centering and Rescaling Predictors (See Notes sections 2.13, 2.14 and 4.7)

## Centering `sleephrs` to ease interaction description

```{r}
smartcle3 <- smartcle3 %>% 
  mutate(sleep_c = sleephrs - mean(sleephrs))

model_int_c <- lm(bmi ~ female * sleep_c, data = smartcle3)
model_int_c
```

## Interpreting Interaction: Centered `sleephrs`

`bmi` = 28.23 - 0.68 `female` + 0.04 centered `sleep_c` - 0.45 `female` x centered `sleep_c`

- Now, 28.23 is the predicted `bmi` for a male who gets the average amount of sleep (7.02 hours)
- And 28.23 - 0.68 = 27.55 is the predicted `bmi` for a female who gets the average amount of sleep.
- So, the main effect of `female` is the predictive difference (female - male) in `bmi` for mean `sleephrs`,
- the product term is the change in the slope of centered `sleephrs_c` on `bmi` for a female rather than a male, and
- the residual standard deviation and the R-squared values remain unchanged from the model before centering.

```{r}
glance(model_int_c) %>% round(., 3)
```

## Plotting `bmi` on centered `sleep_c` by `female`

```{r, echo = FALSE}
ggplot(smartcle3, aes(x = sleep_c, y = bmi, group = female, col = factor(female))) +
    geom_point(alpha = 0.5, size = 2) +
    geom_smooth(method = "lm", se = FALSE) +
    guides(color = FALSE) +
    labs(x = "Sleep Hours, centered", y = "Body Mass Index",
         title = "Model for `bmi` using `sleep_c` and `female`") +
    facet_wrap(~ female, labeller = label_both)
```

## Rescaling?

Centering helped us interpret the main effects in the regression, but it still leaves a scaling problem.

- The female coefficient estimate is much larger than that of sleephrs, but this is misleading, considering that we are comparing the complete change in one variable (sex = female or not) to a 1-hour change in average sleep.
- Gelman and Hill (2007) recommend all continuous predictors be scaled by dividing by 2 standard deviations
    - A 1-unit change in the rescaled predictor corresponds to a change from 1 standard deviation below the mean, to 1 standard deviation above.
    - An unscaled binary (1/0) predictor with 50% probability of occurring will be exactly comparable

## Rescaling to `sleep_z` and re-fitting the model

```{r}
smartcle3 <- smartcle3 %>%
    mutate(sleep_z = (sleephrs - mean(sleephrs)) /
             (2*sd(sleephrs)))

model_int_z <- lm(bmi ~ female * sleep_z, data = smartcle3)

model_int_z
```

## Comparing our Interaction Models

Original Model

- `bmi` = 27.95 + 2.47 `female` + 0.04 `sleephrs` - 0.45 `female` x `sleephrs`

Centered Model

- `bmi` = 28.23 - 0.68 `female` + 0.04 `sleep_c` - 0.45 `female` x `sleep_c`

Centered, Rescaled Model

- `bmi` = 28.23 - 0.68 `female` + 0.12 `sleep_z` - 1.37 `female` x `sleep_z`

## Interpreting the Centered, Rescaled Model

- Main effect of `female`, -0.68, is still the predictive difference (female - male) in `bmi` with `sleephrs` at its mean, 7.02 hours,
- Intercept (28.23) is still the predicted `bmi` for a male who sleeps the mean number of hours, and
- the residual standard deviation and the R-squared values remain unchanged

but now we also have:

- the coefficient of `sleep_z` is the predictive difference in bmi associated with a change in `sleephrs` of 2 standard deviations (from one standard deviation below the mean of 7.02 to one standard deviation above 7.02.)
    - Since sd(sleephrs) is 1.52, this corresponds to a change from 5.50 hours per night to 8.54 hours per night.
- the coefficient of the product term (-1.37) corresponds to the change in the coefficient of `sleep_z` for females as compared to males.

## Plotting the Rescaled, Centered Model

```{r, echo = FALSE}
ggplot(smartcle3, aes(x = sleep_z, y = bmi, 
                      group = female, col = factor(female))) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", size = 1.5) +
    scale_color_discrete(name = "Is subject female?") +
    labs(x = "Sleep Hours, centered and standardized (2 sd)", y = "Body Mass Index",
         title = "Interaction model on centered, rescaled sleephrs")
```

# Two-Factor Analysis of Variance (see Notes Chapter 3)

## How do `female` and `exerany` relate to `bmi`?

```{r}
smart3_sum <- smartcle3 %>%
  group_by(female, exerany) %>%
  summarize(mean.bmi = mean(bmi), sd.bmi = sd(bmi))
```

## Resulting tibble for `smart3_sum`

```{r}
smart3_sum
```

This would be more useful as a plot.

## Building a Means Plot (result on next slide)

```{r, eval = FALSE}
pd <- position_dodge(0.2)

ggplot(smart3_sum, aes(x = exerany, y = mean.bmi, col = factor(female))) +
  geom_errorbar(aes(ymin = mean.bmi - sd.bmi,
                    ymax = mean.bmi + sd.bmi),
                width = 0.2, position = pd) +
  geom_point(size = 2, position = pd) + 
  geom_line(aes(group = female), position = pd) +
  scale_color_discrete(name = "Female?") +
  theme_bw() +
  labs(y = "Body Mass Index", x = "Exercise at all in past 30 days?",
       title = "Observed Means (+/- SD) of BMI by Exercise and Sex")
```

## Means Plot (Do we have a strong interaction effect?)

```{r, echo = FALSE}
pd <- position_dodge(0.2)

ggplot(smart3_sum, aes(x = exerany, y = mean.bmi, col = factor(female))) +
  geom_errorbar(aes(ymin = mean.bmi - sd.bmi,
                    ymax = mean.bmi + sd.bmi),
                width = 0.2, position = pd) +
  geom_point(size = 2, position = pd) + 
  geom_line(aes(group = female), position = pd) +
  scale_color_discrete(name = "Female?") +
  theme_bw() +
  labs(y = "Body Mass Index", x = "Exercise at all in past 30 days?",
       title = "Observed Means (+/- SD) of BMI by Exercise and Sex")
```

## Two-Way ANOVA model with Interaction

```{r}
model2 <- lm(bmi ~ female * exerany, data = smartcle3)

anova(model2)
```

Does it seem like we need the interaction term in this case?

## Summary of Two-Factor ANOVA with Interaction

![](figs/fig02.png)

## What if we wanted the model with no interaction?

Here's the key plot, then...

```{r, eval = FALSE}
p1 <- ggplot(smartcle3, aes(x = factor(female), y = bmi)) + 
    geom_boxplot()
p2 <- ggplot(smartcle3, aes(x = factor(exerany), y = bmi)) +
    geom_boxplot()

gridExtra::grid.arrange(p1, p2, nrow = 1)
```

## Key Plot for Two-Way ANOVA, no interaction

```{r, echo = FALSE}
p1 <- ggplot(smartcle3, aes(x = factor(female), y = bmi)) + 
    geom_boxplot()
p2 <- ggplot(smartcle3, aes(x = factor(exerany), y = bmi)) +
    geom_boxplot()

gridExtra::grid.arrange(p1, p2, nrow = 1)
```

## Two-Way ANOVA model without Interaction

```{r}
model2_noint <- lm(bmi ~ female + exerany, data = smartcle3)

anova(model2_noint)
```

## Summary of Two-Factor No Interaction ANOVA

![](figs/fig03.png)

## Tukey HSD Comparisons (no interaction)

```{r, echo = FALSE}
par(mfrow=c(1,2))
plot(TukeyHSD(aov(bmi ~ factor(female) + factor(exerany), data = smartcle3)))
par(mfrow=c(1,1))
```

## Tukey HSD Comparisons (without interaction)

```{r, echo = FALSE}
TukeyHSD(aov(bmi ~ factor(female) + factor(exerany), data = smartcle3))
```

## Tukey HSD comparisons WITH interaction

```{r, echo = FALSE}
par(mfrow=c(1,3))
plot(TukeyHSD(aov(bmi ~ factor(female) * factor(exerany), data = smartcle3)))
par(mfrow=c(1,1))
```

## Tukey HSD comparisons WITH interaction

![](figs/fig04.png)

## Next Time

- Building a linear regression model
- Cross-validation of a linear model
- Sequential Variable Selection (Stepwise Regression)
  - Forward Selection, Backward Elimination, Allen-Cady approaches
- Best Subsets Variable Selection
  - Adjusted R^2^, bias-corrected AIC, BIC and C~p~
    
These ideas come from Chapters 6-8, mostly.
